{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff38ac14",
   "metadata": {},
   "source": [
    "Take the work we did in the lessons further:\n",
    "\n",
    "- What other types of models (i.e. different classifcation algorithms) could you use?\n",
    "- How do the models compare when trained on term frequency data alone, instead of TF-IDF values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c623ee9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T21:26:40.521760Z",
     "start_time": "2022-09-01T21:26:40.506165Z"
    }
   },
   "outputs": [],
   "source": [
    "import acquire\n",
    "import prepare\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import nltk\n",
    "\n",
    "from env import get_db_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbdf0b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:32:09.389841Z",
     "start_time": "2022-09-01T16:32:07.424863Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM spam\", get_db_url(\"spam_db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87da4e68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T21:25:20.965020Z",
     "start_time": "2022-09-01T21:25:20.877434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id label                                               text\n",
       "0   0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   1   ham                      Ok lar... Joking wif u oni...\n",
       "2   2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   3   ham  U dun say so early hor... U c already then say...\n",
       "4   4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c0eef13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:32:18.669556Z",
     "start_time": "2022-09-01T16:32:18.641670Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "train, validate, test = prepare.train_validate_test_split(df, target = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95d1bdcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:32:30.838125Z",
     "start_time": "2022-09-01T16:32:30.616415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.95%\n",
      "---\n",
      "Train Confusion Matrix\n",
      "actual              ham  spam\n",
      "predicted_log_reg            \n",
      "ham                2700    94\n",
      "spam                  1   324\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      2701\n",
      "        spam       1.00      0.78      0.87       418\n",
      "\n",
      "    accuracy                           0.97      3119\n",
      "   macro avg       0.98      0.89      0.93      3119\n",
      "weighted avg       0.97      0.97      0.97      3119\n",
      "\n",
      "Accuracy: 95.67%\n",
      "---\n",
      "Validate Confusion Matrix\n",
      "actual              ham  spam\n",
      "predicted_log_reg            \n",
      "ham                1158    58\n",
      "spam                  0   122\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      1.00      0.98      1158\n",
      "        spam       1.00      0.68      0.81       180\n",
      "\n",
      "    accuracy                           0.96      1338\n",
      "   macro avg       0.98      0.84      0.89      1338\n",
      "weighted avg       0.96      0.96      0.95      1338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train = tfidf.fit_transform(train.text)\n",
    "X_validate = tfidf.transform(validate.text)\n",
    "X_test = tfidf.transform(test.text)\n",
    "y_train = train.label\n",
    "y_validate = validate.label\n",
    "y_test = test.label\n",
    "\n",
    "train_results_tfidf=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_tfidf = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_tfidf = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train_results_tfidf['predicted_log_reg'] = lm.predict(X_train)\n",
    "validate_results_tfidf['predicted_log_reg'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_tfidf.actual, train_results_tfidf.predicted_log_reg)))\n",
    "print('---')\n",
    "print('Train Confusion Matrix')\n",
    "print(pd.crosstab(train_results_tfidf.predicted_log_reg, train_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_tfidf.actual, train_results_tfidf.predicted_log_reg))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_tfidf.actual, validate_results_tfidf.predicted_log_reg)))\n",
    "print('---')\n",
    "print('Validate Confusion Matrix')\n",
    "print(pd.crosstab(validate_results_tfidf.predicted_log_reg, validate_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_tfidf.actual, validate_results_tfidf.predicted_log_reg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a9ca2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e9b5ccf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:34:17.022506Z",
     "start_time": "2022-09-01T16:34:16.731437Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth = 40).fit(X_train, y_train)\n",
    "\n",
    "train_results_tfidf['predicted_rf'] = rf.predict(X_train)\n",
    "validate_results_tfidf['predicted_rf'] = rf.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8ec75ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:34:24.563412Z",
     "start_time": "2022-09-01T16:34:24.424126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.01%\n",
      "---\n",
      "Train Confusion Matrix\n",
      "actual         ham  spam\n",
      "predicted_rf            \n",
      "ham           2701    31\n",
      "spam             0   387\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      2701\n",
      "        spam       1.00      0.93      0.96       418\n",
      "\n",
      "    accuracy                           0.99      3119\n",
      "   macro avg       0.99      0.96      0.98      3119\n",
      "weighted avg       0.99      0.99      0.99      3119\n",
      "\n",
      "Accuracy: 96.26%\n",
      "---\n",
      "Validate Confusion Matrix\n",
      "actual         ham  spam\n",
      "predicted_rf            \n",
      "ham           1158    50\n",
      "spam             0   130\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      1158\n",
      "        spam       1.00      0.72      0.84       180\n",
      "\n",
      "    accuracy                           0.96      1338\n",
      "   macro avg       0.98      0.86      0.91      1338\n",
      "weighted avg       0.96      0.96      0.96      1338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_tfidf.actual, train_results_tfidf.predicted_rf)))\n",
    "print('---')\n",
    "print('Train Confusion Matrix')\n",
    "print(pd.crosstab(train_results_tfidf.predicted_rf, train_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_tfidf.actual, train_results_tfidf.predicted_rf))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_tfidf.actual, validate_results_tfidf.predicted_rf)))\n",
    "print('---')\n",
    "print('Validate Confusion Matrix')\n",
    "print(pd.crosstab(validate_results_tfidf.predicted_rf, validate_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_tfidf.actual, validate_results_tfidf.predicted_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fba97c",
   "metadata": {},
   "source": [
    "**Takeaway**\n",
    " - Similar results to tfidf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47a430",
   "metadata": {},
   "source": [
    "### Trying CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d78dfd09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:35:40.439705Z",
     "start_time": "2022-09-01T16:35:40.213285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.71%\n",
      "---\n",
      "Train Confusion Matrix\n",
      "actual              ham  spam\n",
      "predicted_log_reg            \n",
      "ham                2701     9\n",
      "spam                  0   409\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      2701\n",
      "        spam       1.00      0.98      0.99       418\n",
      "\n",
      "    accuracy                           1.00      3119\n",
      "   macro avg       1.00      0.99      0.99      3119\n",
      "weighted avg       1.00      1.00      1.00      3119\n",
      "\n",
      "Accuracy: 97.38%\n",
      "---\n",
      "Validate Confusion Matrix\n",
      "actual              ham  spam\n",
      "predicted_log_reg            \n",
      "ham                1157    34\n",
      "spam                  1   146\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      1158\n",
      "        spam       0.99      0.81      0.89       180\n",
      "\n",
      "    accuracy                           0.97      1338\n",
      "   macro avg       0.98      0.91      0.94      1338\n",
      "weighted avg       0.97      0.97      0.97      1338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "X_train = cv.fit_transform(train.text)\n",
    "X_validate = cv.transform(validate.text)\n",
    "X_test = cv.transform(test.text)\n",
    "y_train = train.label\n",
    "y_validate = validate.label\n",
    "y_test = test.label\n",
    "\n",
    "train_results_cv=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_cv = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_cv = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train_results_cv['predicted_log_reg'] = lm.predict(X_train)\n",
    "validate_results_cv['predicted_log_reg'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_cv.actual, train_results_cv.predicted_log_reg)))\n",
    "print('---')\n",
    "print('Train Confusion Matrix')\n",
    "print(pd.crosstab(train_results_cv.predicted_log_reg, train_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_cv.actual, train_results_cv.predicted_log_reg))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_cv.actual, validate_results_cv.predicted_log_reg)))\n",
    "print('---')\n",
    "print('Validate Confusion Matrix')\n",
    "print(pd.crosstab(validate_results_cv.predicted_log_reg, validate_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_cv.actual, validate_results_cv.predicted_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0bc1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbffca4a",
   "metadata": {},
   "source": [
    "## Trying RF with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c846179a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:36:26.180822Z",
     "start_time": "2022-09-01T16:36:25.779234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.78%\n",
      "---\n",
      "Train Confusion Matrix\n",
      "actual         ham  spam\n",
      "predicted_rf            \n",
      "ham           2701    38\n",
      "spam             0   380\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      2701\n",
      "        spam       1.00      0.91      0.95       418\n",
      "\n",
      "    accuracy                           0.99      3119\n",
      "   macro avg       0.99      0.95      0.97      3119\n",
      "weighted avg       0.99      0.99      0.99      3119\n",
      "\n",
      "Accuracy: 95.89%\n",
      "---\n",
      "Validate Confusion Matrix\n",
      "actual         ham  spam\n",
      "predicted_rf            \n",
      "ham           1158    55\n",
      "spam             0   125\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      1.00      0.98      1158\n",
      "        spam       1.00      0.69      0.82       180\n",
      "\n",
      "    accuracy                           0.96      1338\n",
      "   macro avg       0.98      0.85      0.90      1338\n",
      "weighted avg       0.96      0.96      0.96      1338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "X_train = cv.fit_transform(train.text)\n",
    "X_validate = cv.transform(validate.text)\n",
    "X_test = cv.transform(test.text)\n",
    "y_train = train.label\n",
    "y_validate = validate.label\n",
    "y_test = test.label\n",
    "\n",
    "train_results_cv=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_cv = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_cv = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=40).fit(X_train, y_train)\n",
    "\n",
    "train_results_cv['predicted_rf'] = rf.predict(X_train)\n",
    "validate_results_cv['predicted_rf'] = rf.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_cv.actual, train_results_cv.predicted_rf)))\n",
    "print('---')\n",
    "print('Train Confusion Matrix')\n",
    "print(pd.crosstab(train_results_cv.predicted_rf, train_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_cv.actual, train_results_cv.predicted_rf))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_cv.actual, validate_results_cv.predicted_rf)))\n",
    "print('---')\n",
    "print('Validate Confusion Matrix')\n",
    "print(pd.crosstab(validate_results_cv.predicted_rf, validate_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_cv.actual, validate_results_cv.predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b814a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d2caef7",
   "metadata": {},
   "source": [
    "### Clean Data Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ca6d4cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:37:10.336141Z",
     "start_time": "2022-09-01T16:37:09.000633Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_and_lem_df = df.copy()\n",
    "clean_and_lem_df['lem'] = df.text.apply(prepare.basic_clean).apply(prepare.tokenize).apply(prepare.lemmatize).apply(prepare.remove_stopwords,\n",
    "                                                       extra_words = [],\n",
    "                                                       exclude_words = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1f27d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:37:15.257720Z",
     "start_time": "2022-09-01T16:37:15.240092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id label                                               text\n",
       "0   0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   1   ham                      Ok lar... Joking wif u oni...\n",
       "2   2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   3   ham  U dun say so early hor... U c already then say...\n",
       "4   4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aadfff38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:37:24.028864Z",
     "start_time": "2022-09-01T16:37:24.018806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah ' think go usf life around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id label                                               text  \\\n",
       "0   0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   1   ham                      Ok lar... Joking wif u oni...   \n",
       "2   2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   3   ham  U dun say so early hor... U c already then say...   \n",
       "4   4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                                 lem  \n",
       "0  go jurong point crazy available bugis n great ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...  \n",
       "3                u dun say early hor u c already say  \n",
       "4              nah ' think go usf life around though  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "clean_and_lem_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83a1412d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:37:32.208428Z",
     "start_time": "2022-09-01T16:37:32.182601Z"
    }
   },
   "outputs": [],
   "source": [
    "#Split\n",
    "train, validate, test = prepare.train_validate_test_split(clean_and_lem_df, target = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3ba9bf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:38:19.569948Z",
     "start_time": "2022-09-01T16:38:19.384240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.36%\n",
      "---\n",
      "Train Confusion Matrix\n",
      "actual              ham  spam\n",
      "predicted_log_reg            \n",
      "ham                2700    19\n",
      "spam                  1   399\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      1.00      2701\n",
      "        spam       1.00      0.95      0.98       418\n",
      "\n",
      "    accuracy                           0.99      3119\n",
      "   macro avg       1.00      0.98      0.99      3119\n",
      "weighted avg       0.99      0.99      0.99      3119\n",
      "\n",
      "Accuracy: 97.01%\n",
      "---\n",
      "Validate Confusion Matrix\n",
      "actual              ham  spam\n",
      "predicted_log_reg            \n",
      "ham                1157    39\n",
      "spam                  1   141\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      1158\n",
      "        spam       0.99      0.78      0.88       180\n",
      "\n",
      "    accuracy                           0.97      1338\n",
      "   macro avg       0.98      0.89      0.93      1338\n",
      "weighted avg       0.97      0.97      0.97      1338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "X_train = cv.fit_transform(train.lem)\n",
    "X_validate = cv.transform(validate.lem)\n",
    "X_test = cv.transform(test.lem)\n",
    "y_train = train.label\n",
    "y_validate = validate.label\n",
    "y_test = test.label\n",
    "\n",
    "train_results_cv=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_cv = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_cv = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train_results_cv['predicted_log_reg'] = lm.predict(X_train)\n",
    "validate_results_cv['predicted_log_reg'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_cv.actual, train_results_cv.predicted_log_reg)))\n",
    "print('---')\n",
    "print('Train Confusion Matrix')\n",
    "print(pd.crosstab(train_results_cv.predicted_log_reg, train_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_cv.actual, train_results_cv.predicted_log_reg))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_cv.actual, validate_results_cv.predicted_log_reg)))\n",
    "print('---')\n",
    "print('Validate Confusion Matrix')\n",
    "print(pd.crosstab(validate_results_cv.predicted_log_reg, validate_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_cv.actual, validate_results_cv.predicted_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf868fa",
   "metadata": {},
   "source": [
    "# Final takeaways:\n",
    " - I'm not seeing large difference between models.  \n",
    " - Hoping News data will make model differences clear\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e72d3",
   "metadata": {},
   "source": [
    "# News Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaa59bcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:40:13.405106Z",
     "start_time": "2022-09-01T16:40:13.249792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing from csv\n"
     ]
    }
   ],
   "source": [
    "# import News\n",
    "news = prepare.create_prepared_news_df()\n",
    "target = 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7929ece8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:40:21.812417Z",
     "start_time": "2022-09-01T16:40:21.800801Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "train, validate, test = prepare.train_validate_test_split(news, target = 'category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a05ee15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:40:40.445236Z",
     "start_time": "2022-09-01T16:40:40.394161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       1.00      1.00      1.00        14\n",
      "entertainment       1.00      1.00      1.00        14\n",
      "       sports       1.00      1.00      1.00        14\n",
      "   technology       1.00      1.00      1.00        14\n",
      "\n",
      "     accuracy                           1.00        56\n",
      "    macro avg       1.00      1.00      1.00        56\n",
      " weighted avg       1.00      1.00      1.00        56\n",
      "\n",
      "Accuracy: 54.17%\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.00      0.00      0.00         6\n",
      "entertainment       1.00      0.83      0.91         6\n",
      "       sports       1.00      1.00      1.00         6\n",
      "   technology       0.25      0.33      0.29         6\n",
      "\n",
      "     accuracy                           0.54        24\n",
      "    macro avg       0.56      0.54      0.55        24\n",
      " weighted avg       0.56      0.54      0.55        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count vector model\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X_train = cv.fit_transform(train.lemmatized)\n",
    "X_validate = cv.transform(validate.lemmatized)\n",
    "X_test = cv.transform(test.lemmatized)\n",
    "y_train = train[target]\n",
    "y_validate = validate[target]\n",
    "y_test = test[target]\n",
    "\n",
    "train_results_cv=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_cv = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_cv = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train_results_cv['predicted_log_reg'] = lm.predict(X_train)\n",
    "validate_results_cv['predicted_log_reg'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_cv.actual, train_results_cv.predicted_log_reg)))\n",
    "# print('---')\n",
    "# print('Train Confusion Matrix')\n",
    "# print(pd.crosstab(train_results_cv.predicted_log_reg, train_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_cv.actual, train_results_cv.predicted_log_reg))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_cv.actual, validate_results_cv.predicted_log_reg)))\n",
    "# print('---')\n",
    "# print('Validate Confusion Matrix')\n",
    "# print(pd.crosstab(validate_results_cv.predicted_log_reg, validate_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_cv.actual, validate_results_cv.predicted_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a1bde61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:41:51.686713Z",
     "start_time": "2022-09-01T16:41:51.635603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       1.00      1.00      1.00        14\n",
      "entertainment       1.00      1.00      1.00        14\n",
      "       sports       1.00      1.00      1.00        14\n",
      "   technology       1.00      1.00      1.00        14\n",
      "\n",
      "     accuracy                           1.00        56\n",
      "    macro avg       1.00      1.00      1.00        56\n",
      " weighted avg       1.00      1.00      1.00        56\n",
      "\n",
      "Accuracy: 41.67%\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.00      0.00      0.00         6\n",
      "entertainment       0.42      0.83      0.56         6\n",
      "       sports       0.83      0.83      0.83         6\n",
      "   technology       0.00      0.00      0.00         6\n",
      "\n",
      "     accuracy                           0.42        24\n",
      "    macro avg       0.31      0.42      0.35        24\n",
      " weighted avg       0.31      0.42      0.35        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Bigrams\n",
    "cv = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "X_train = cv.fit_transform(train.lemmatized)\n",
    "X_validate = cv.transform(validate.lemmatized)\n",
    "X_test = cv.transform(test.lemmatized)\n",
    "y_train = train[target]\n",
    "y_validate = validate[target]\n",
    "y_test = test[target]\n",
    "\n",
    "train_results_cv=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_cv = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_cv = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train_results_cv['predicted_log_reg_bigrams'] = lm.predict(X_train)\n",
    "validate_results_cv['predicted_log_reg_bigrams'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_cv.actual, train_results_cv.predicted_log_reg_bigrams)))\n",
    "# print('---')\n",
    "# print('Train Confusion Matrix')\n",
    "# print(pd.crosstab(train_results_cv.predicted_log_reg_bigrams, train_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_cv.actual, train_results_cv.predicted_log_reg_bigrams))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_cv.actual, validate_results_cv.predicted_log_reg_bigrams)))\n",
    "# print('---')\n",
    "# print('Validate Confusion Matrix')\n",
    "# print(pd.crosstab(validate_results_cv.predicted_log_reg_bigrams, validate_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_cv.actual, validate_results_cv.predicted_log_reg_bigrams))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16ab5f98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:42:36.597912Z",
     "start_time": "2022-09-01T16:42:36.562481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       1.00      1.00      1.00        14\n",
      "entertainment       1.00      1.00      1.00        14\n",
      "       sports       1.00      1.00      1.00        14\n",
      "   technology       1.00      1.00      1.00        14\n",
      "\n",
      "     accuracy                           1.00        56\n",
      "    macro avg       1.00      1.00      1.00        56\n",
      " weighted avg       1.00      1.00      1.00        56\n",
      "\n",
      "Accuracy: 58.33%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.00      0.00      0.00         6\n",
      "entertainment       1.00      1.00      1.00         6\n",
      "       sports       0.86      1.00      0.92         6\n",
      "   technology       0.29      0.33      0.31         6\n",
      "\n",
      "     accuracy                           0.58        24\n",
      "    macro avg       0.54      0.58      0.56        24\n",
      " weighted avg       0.54      0.58      0.56        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bayes?\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X_train = cv.fit_transform(train.lemmatized)\n",
    "X_validate = cv.transform(validate.lemmatized)\n",
    "X_test = cv.transform(test.lemmatized)\n",
    "y_train = train[target]\n",
    "y_validate = validate[target]\n",
    "y_test = test[target]\n",
    "\n",
    "train_results_cv=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_cv = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_cv = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "train_results_cv['predicted_nb'] = lm.predict(X_train)\n",
    "validate_results_cv['predicted_nb'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_cv.actual, train_results_cv.predicted_nb)))\n",
    "print('---')\n",
    "# print('Train Confusion Matrix')\n",
    "# print(pd.crosstab(train_results_cv.predicted_nb, train_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_cv.actual, train_results_cv.predicted_nb))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_cv.actual, validate_results_cv.predicted_nb)))\n",
    "print('---')\n",
    "# print('Validate Confusion Matrix')\n",
    "# print(pd.crosstab(validate_results_cv.predicted_nb, validate_results_cv.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_cv.actual, validate_results_cv.predicted_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64db7c13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:42:59.237193Z",
     "start_time": "2022-09-01T16:42:59.201142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       1.00      1.00      1.00        14\n",
      "entertainment       1.00      1.00      1.00        14\n",
      "       sports       1.00      1.00      1.00        14\n",
      "   technology       1.00      1.00      1.00        14\n",
      "\n",
      "     accuracy                           1.00        56\n",
      "    macro avg       1.00      1.00      1.00        56\n",
      " weighted avg       1.00      1.00      1.00        56\n",
      "\n",
      "Accuracy: 58.33%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.00      0.00      0.00         6\n",
      "entertainment       1.00      1.00      1.00         6\n",
      "       sports       0.86      1.00      0.92         6\n",
      "   technology       0.29      0.33      0.31         6\n",
      "\n",
      "     accuracy                           0.58        24\n",
      "    macro avg       0.54      0.58      0.56        24\n",
      " weighted avg       0.54      0.58      0.56        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tfidf\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train = tfidf.fit_transform(train.lemmatized)\n",
    "X_validate = tfidf.transform(validate.lemmatized)\n",
    "X_test = tfidf.transform(test.lemmatized)\n",
    "y_train = train[target]\n",
    "y_validate = validate[target]\n",
    "y_test = test[target]\n",
    "\n",
    "train_results_tfidf=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_tfidf = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_tfidf = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "train_results_tfidf['predicted_nb'] = lm.predict(X_train)\n",
    "validate_results_tfidf['predicted_nb'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_tfidf.actual, train_results_tfidf.predicted_nb)))\n",
    "print('---')\n",
    "# print('Train Confusion Matrix')\n",
    "# print(pd.crosstab(train_results_tfidf.predicted_nb, train_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_tfidf.actual, train_results_tfidf.predicted_nb))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_tfidf.actual, validate_results_tfidf.predicted_nb)))\n",
    "print('---')\n",
    "# print('Validate Confusion Matrix')\n",
    "# print(pd.crosstab(validate_results_tfidf.predicted_nb, validate_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_tfidf.actual, validate_results_tfidf.predicted_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6842835b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:43:21.343531Z",
     "start_time": "2022-09-01T16:43:21.308429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       1.00      1.00      1.00        14\n",
      "entertainment       1.00      1.00      1.00        14\n",
      "       sports       1.00      1.00      1.00        14\n",
      "   technology       1.00      1.00      1.00        14\n",
      "\n",
      "     accuracy                           1.00        56\n",
      "    macro avg       1.00      1.00      1.00        56\n",
      " weighted avg       1.00      1.00      1.00        56\n",
      "\n",
      "Accuracy: 41.67%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.12      0.17      0.14         6\n",
      "entertainment       0.75      0.50      0.60         6\n",
      "       sports       0.86      1.00      0.92         6\n",
      "   technology       0.00      0.00      0.00         6\n",
      "\n",
      "     accuracy                           0.42        24\n",
      "    macro avg       0.43      0.42      0.42        24\n",
      " weighted avg       0.43      0.42      0.42        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# W/ Bigrams\n",
    "tfidf = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "X_train = tfidf.fit_transform(train.lemmatized)\n",
    "X_validate = tfidf.transform(validate.lemmatized)\n",
    "X_test = tfidf.transform(test.lemmatized)\n",
    "y_train = train[target]\n",
    "y_validate = validate[target]\n",
    "y_test = test[target]\n",
    "\n",
    "train_results_tfidf=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_tfidf = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_tfidf = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "train_results_tfidf['predicted_nb'] = lm.predict(X_train)\n",
    "validate_results_tfidf['predicted_nb'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_tfidf.actual, train_results_tfidf.predicted_nb)))\n",
    "print('---')\n",
    "# print('Train Confusion Matrix')\n",
    "# print(pd.crosstab(train_results_tfidf.predicted_nb, train_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_tfidf.actual, train_results_tfidf.predicted_nb))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_tfidf.actual, validate_results_tfidf.predicted_nb)))\n",
    "print('---')\n",
    "# print('Validate Confusion Matrix')\n",
    "# print(pd.crosstab(validate_results_tfidf.predicted_nb, validate_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_tfidf.actual, validate_results_tfidf.predicted_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8a588c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:43:48.885649Z",
     "start_time": "2022-09-01T16:43:48.846749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       1.00      1.00      1.00        14\n",
      "entertainment       1.00      1.00      1.00        14\n",
      "       sports       1.00      1.00      1.00        14\n",
      "   technology       1.00      1.00      1.00        14\n",
      "\n",
      "     accuracy                           1.00        56\n",
      "    macro avg       1.00      1.00      1.00        56\n",
      " weighted avg       1.00      1.00      1.00        56\n",
      "\n",
      "Accuracy: 58.33%\n",
      "---\n",
      "---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.00      0.00      0.00         6\n",
      "entertainment       1.00      1.00      1.00         6\n",
      "       sports       1.00      1.00      1.00         6\n",
      "   technology       0.25      0.33      0.29         6\n",
      "\n",
      "     accuracy                           0.58        24\n",
      "    macro avg       0.56      0.58      0.57        24\n",
      " weighted avg       0.56      0.58      0.57        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Words w/ bigrams\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "X_train = tfidf.fit_transform(train.lemmatized)\n",
    "X_validate = tfidf.transform(validate.lemmatized)\n",
    "X_test = tfidf.transform(test.lemmatized)\n",
    "y_train = train[target]\n",
    "y_validate = validate[target]\n",
    "y_test = test[target]\n",
    "\n",
    "train_results_tfidf=pd.DataFrame(dict(actual = y_train))\n",
    "validate_results_tfidf = pd.DataFrame(dict(actual = y_validate))\n",
    "test_results_tfidf = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "lm = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "train_results_tfidf['predicted_nb'] = lm.predict(X_train)\n",
    "validate_results_tfidf['predicted_nb'] = lm.predict(X_validate)\n",
    "# test_results['predicted'] = lm.predict(X_test)\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(train_results_tfidf.actual, train_results_tfidf.predicted_nb)))\n",
    "print('---')\n",
    "# print('Train Confusion Matrix')\n",
    "# print(pd.crosstab(train_results_tfidf.predicted_nb, train_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(train_results_tfidf.actual, train_results_tfidf.predicted_nb))\n",
    "\n",
    "\n",
    "print('Accuracy: {:.2%}'.format(accuracy_score(validate_results_tfidf.actual, validate_results_tfidf.predicted_nb)))\n",
    "print('---')\n",
    "# print('Validate Confusion Matrix')\n",
    "# print(pd.crosstab(validate_results_tfidf.predicted_nb, validate_results_tfidf.actual))\n",
    "print('---')\n",
    "print(classification_report(validate_results_tfidf.actual, validate_results_tfidf.predicted_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37dcc4",
   "metadata": {},
   "source": [
    "## Takeaway:\n",
    "- Model accuracy is always 100%, but validation is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "448c2f6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:45:02.161382Z",
     "start_time": "2022-09-01T16:45:02.144395Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_words(vectorizer, class_model, ngrams_range_value, train, validate, target, print_results = True):\n",
    "    \"\"\"Performs classification modeling of lemmatized data. Outputs (and returns) classification reports for train and validate/test.\n",
    "    \n",
    "    vectorizer: the type of feature extraction method, such as Count Vectorizer or tf-idf\n",
    "    class_model: the classification model to use\n",
    "    ngrams_range_value: whether to use unigram, bigrams, etc. for the feature extraction\n",
    "    train and test sets as well as the target variable\"\"\"\n",
    "    \n",
    "    feature_extraction_method = vectorizer(ngram_range=ngrams_range_value)\n",
    "\n",
    "    X_train = feature_extraction_method.fit_transform(train.lemmatized)\n",
    "    X_validate = feature_extraction_method.transform(validate.lemmatized)\n",
    "    X_test = feature_extraction_method.transform(test.lemmatized)\n",
    "    y_train = train[target]\n",
    "    y_validate = validate[target]\n",
    "    # y_test = test[target]\n",
    "\n",
    "    train_results=pd.DataFrame(dict(actual = y_train))\n",
    "    validate_results = pd.DataFrame(dict(actual = y_validate))\n",
    "    # test_results = pd.DataFrame(dict(actual = y_test))\n",
    "\n",
    "    model_to_use = class_model.fit(X_train, y_train)\n",
    "\n",
    "    train_results['predicted'] = model_to_use.predict(X_train)\n",
    "    validate_results['predicted'] = model_to_use.predict(X_validate)\n",
    "    # test_results['predicted'] = model_to_use.predict(X_test)\n",
    "    train_class_report = classification_report(train_results.actual, train_results.predicted, output_dict = True)\n",
    "    validate_class_report = classification_report(validate_results.actual, validate_results.predicted,output_dict=True)\n",
    "    if print_results:\n",
    "        print('Accuracy: {:.2%}'.format(accuracy_score(train_results.actual, train_results.predicted)))\n",
    "        print('---')\n",
    "        # print('Train Confusion Matrix')\n",
    "        # print(pd.crosstab(train_results_tfidf.predicted, train_results_tfidf.actual))\n",
    "        print('---')\n",
    "        print(pd.DataFrame(train_class_report))\n",
    "\n",
    "\n",
    "        print('Accuracy: {:.2%}'.format(accuracy_score(validate_results.actual, validate_results.predicted)))\n",
    "        print('---')\n",
    "        # print('Validate Confusion Matrix')\n",
    "        # print(pd.crosstab(validate_results_tfidf.predicted, validate_results_tfidf.actual))\n",
    "        print('---')\n",
    "        print(pd.DataFrame(validate_class_report))\n",
    "    \n",
    "    return train_class_report, validate_class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f29c8fdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T16:45:11.161479Z",
     "start_time": "2022-09-01T16:45:10.791154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "RandomForestClassifier(random_state=123) <class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "Accuracy: 100.00%\n",
      "---\n",
      "---\n",
      "           business  entertainment  sports  technology  accuracy  macro avg  \\\n",
      "precision       1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "recall          1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "f1-score        1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "support        14.0           14.0    14.0        14.0       1.0       56.0   \n",
      "\n",
      "           weighted avg  \n",
      "precision           1.0  \n",
      "recall              1.0  \n",
      "f1-score            1.0  \n",
      "support            56.0  \n",
      "Accuracy: 58.33%\n",
      "---\n",
      "---\n",
      "           business  entertainment    sports  technology  accuracy  macro avg  \\\n",
      "precision  0.285714       0.833333  1.000000    0.333333  0.583333   0.613095   \n",
      "recall     0.333333       0.833333  0.833333    0.333333  0.583333   0.583333   \n",
      "f1-score   0.307692       0.833333  0.909091    0.333333  0.583333   0.595862   \n",
      "support    6.000000       6.000000  6.000000    6.000000  0.583333  24.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.613095  \n",
      "recall         0.583333  \n",
      "f1-score       0.595862  \n",
      "support       24.000000  \n",
      "----\n",
      "LogisticRegression() <class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "Accuracy: 100.00%\n",
      "---\n",
      "---\n",
      "           business  entertainment  sports  technology  accuracy  macro avg  \\\n",
      "precision       1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "recall          1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "f1-score        1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "support        14.0           14.0    14.0        14.0       1.0       56.0   \n",
      "\n",
      "           weighted avg  \n",
      "precision           1.0  \n",
      "recall              1.0  \n",
      "f1-score            1.0  \n",
      "support            56.0  \n",
      "Accuracy: 54.17%\n",
      "---\n",
      "---\n",
      "           business  entertainment  sports  technology  accuracy  macro avg  \\\n",
      "precision       0.0       1.000000     1.0    0.250000  0.541667   0.562500   \n",
      "recall          0.0       0.833333     1.0    0.333333  0.541667   0.541667   \n",
      "f1-score        0.0       0.909091     1.0    0.285714  0.541667   0.548701   \n",
      "support         6.0       6.000000     6.0    6.000000  0.541667  24.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.562500  \n",
      "recall         0.541667  \n",
      "f1-score       0.548701  \n",
      "support       24.000000  \n",
      "----\n",
      "DecisionTreeClassifier() <class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "Accuracy: 100.00%\n",
      "---\n",
      "---\n",
      "           business  entertainment  sports  technology  accuracy  macro avg  \\\n",
      "precision       1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "recall          1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "f1-score        1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "support        14.0           14.0    14.0        14.0       1.0       56.0   \n",
      "\n",
      "           weighted avg  \n",
      "precision           1.0  \n",
      "recall              1.0  \n",
      "f1-score            1.0  \n",
      "support            56.0  \n",
      "Accuracy: 33.33%\n",
      "---\n",
      "---\n",
      "           business  entertainment    sports  technology  accuracy  macro avg  \\\n",
      "precision       0.0       1.000000  0.714286    0.142857  0.333333   0.464286   \n",
      "recall          0.0       0.333333  0.833333    0.166667  0.333333   0.333333   \n",
      "f1-score        0.0       0.500000  0.769231    0.153846  0.333333   0.355769   \n",
      "support         6.0       6.000000  6.000000    6.000000  0.333333  24.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.464286  \n",
      "recall         0.333333  \n",
      "f1-score       0.355769  \n",
      "support       24.000000  \n",
      "----\n",
      "RandomForestClassifier(random_state=123) <class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "Accuracy: 100.00%\n",
      "---\n",
      "---\n",
      "           business  entertainment  sports  technology  accuracy  macro avg  \\\n",
      "precision       1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "recall          1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "f1-score        1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "support        14.0           14.0    14.0        14.0       1.0       56.0   \n",
      "\n",
      "           weighted avg  \n",
      "precision           1.0  \n",
      "recall              1.0  \n",
      "f1-score            1.0  \n",
      "support            56.0  \n",
      "Accuracy: 62.50%\n",
      "---\n",
      "---\n",
      "           business  entertainment    sports  technology  accuracy  macro avg  \\\n",
      "precision  0.250000       0.833333  1.000000    0.444444     0.625   0.631944   \n",
      "recall     0.166667       0.833333  0.833333    0.666667     0.625   0.625000   \n",
      "f1-score   0.200000       0.833333  0.909091    0.533333     0.625   0.618939   \n",
      "support    6.000000       6.000000  6.000000    6.000000     0.625  24.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.631944  \n",
      "recall         0.625000  \n",
      "f1-score       0.618939  \n",
      "support       24.000000  \n",
      "----\n",
      "LogisticRegression() <class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "Accuracy: 100.00%\n",
      "---\n",
      "---\n",
      "           business  entertainment  sports  technology  accuracy  macro avg  \\\n",
      "precision       1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "recall          1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "f1-score        1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "support        14.0           14.0    14.0        14.0       1.0       56.0   \n",
      "\n",
      "           weighted avg  \n",
      "precision           1.0  \n",
      "recall              1.0  \n",
      "f1-score            1.0  \n",
      "support            56.0  \n",
      "Accuracy: 54.17%\n",
      "---\n",
      "---\n",
      "           business  entertainment  sports  technology  accuracy  macro avg  \\\n",
      "precision       0.0       1.000000     1.0    0.222222  0.541667   0.555556   \n",
      "recall          0.0       0.833333     1.0    0.333333  0.541667   0.541667   \n",
      "f1-score        0.0       0.909091     1.0    0.266667  0.541667   0.543939   \n",
      "support         6.0       6.000000     6.0    6.000000  0.541667  24.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.555556  \n",
      "recall         0.541667  \n",
      "f1-score       0.543939  \n",
      "support       24.000000  \n",
      "----\n",
      "DecisionTreeClassifier() <class 'sklearn.feature_extraction.text.TfidfVectorizer'>\n",
      "Accuracy: 100.00%\n",
      "---\n",
      "---\n",
      "           business  entertainment  sports  technology  accuracy  macro avg  \\\n",
      "precision       1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "recall          1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "f1-score        1.0            1.0     1.0         1.0       1.0        1.0   \n",
      "support        14.0           14.0    14.0        14.0       1.0       56.0   \n",
      "\n",
      "           weighted avg  \n",
      "precision           1.0  \n",
      "recall              1.0  \n",
      "f1-score            1.0  \n",
      "support            56.0  \n",
      "Accuracy: 29.17%\n",
      "---\n",
      "---\n",
      "           business  entertainment    sports  technology  accuracy  macro avg  \\\n",
      "precision  0.100000       0.571429  1.000000         0.0  0.291667   0.417857   \n",
      "recall     0.166667       0.666667  0.333333         0.0  0.291667   0.291667   \n",
      "f1-score   0.125000       0.615385  0.500000         0.0  0.291667   0.310096   \n",
      "support    6.000000       6.000000  6.000000         6.0  0.291667  24.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.417857  \n",
      "recall         0.291667  \n",
      "f1-score       0.310096  \n",
      "support       24.000000  \n"
     ]
    }
   ],
   "source": [
    "vectorizers = [CountVectorizer, TfidfVectorizer]\n",
    "class_models = [RandomForestClassifier(random_state=123), LogisticRegression(), DecisionTreeClassifier()]\n",
    "for v in vectorizers:\n",
    "    for m in class_models:\n",
    "        print(\"----\")\n",
    "        print(m, v)\n",
    "        \n",
    "        train_class_report, validate_class_report = model_words(v, m, (1,1), train, validate, target, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb7695",
   "metadata": {},
   "source": [
    "## Take away:\n",
    "- I think Accuracy may not be the metric worth looking at.  \n",
    "- I think my ability to understand the results is possible conflict.\n",
    "- I can run code... be happy with that, Codeup... I just don't know what it means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d55f49e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
